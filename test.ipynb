{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "= VectorDatabase initialized =\n",
      "  - loading data into ChromaDB \n",
      "     - collection faq deleted.\n",
      "     - loading faq done.\n",
      "     - collection insurance deleted.\n",
      "     - loading insurance done.\n",
      "     - collection finance deleted.\n",
      "     - loading finance done.\n",
      "= VectorDatabase initialized =\n",
      "= Retriever initialized =\n",
      "= Ground truth accuracy =\n",
      "Retrieval accuracy: 85.33%\n",
      "Category: insurance, Accuracy: 88.00%\n",
      "Category: finance, Accuracy: 72.00%\n",
      "Category: faq, Accuracy: 96.00%\n"
     ]
    }
   ],
   "source": [
    "from Utils import *\n",
    "db = VectorDatabase()\n",
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:4000\"\n",
    "db.initialize_process(chunk_size=256 ,chunk_overlap=200)\n",
    "from Utils import *\n",
    "retriever = Retriever()\n",
    "retriever.process_questions(method='Vector')\n",
    "\n",
    "evaluator = Evaluation()\n",
    "\n",
    "evaluator.output_evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resource module not available on Windows\n",
      "= VectorDatabase initialized =\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\marks\\AppData\\Local\\Temp\\jieba.cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "= Retriever initialized =\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model cost 0.629 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "= Ground truth accuracy =\n",
      "Retrieval accuracy: 79.33%\n",
      "Category: insurance, Accuracy: 88.00%\n",
      "Category: finance, Accuracy: 58.00%\n",
      "Category: faq, Accuracy: 92.00%\n"
     ]
    }
   ],
   "source": [
    "from Utils import *\n",
    "retriever = Retriever()\n",
    "retriever.process_questions(method='BM25_Vector')\n",
    "\n",
    "evaluator = Evaluation()\n",
    "\n",
    "evaluator.output_evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Utils import *\n",
    "db = VectorDatabase()\n",
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:4000\"\n",
    "db.initialize_process(chunk_size=400 ,chunk_overlap=300)\n",
    "from Utils import *\n",
    "retriever = Retriever()\n",
    "retriever.process_questions(method='Vector')\n",
    "\n",
    "evaluator = Evaluation()\n",
    "\n",
    "evaluator.output_evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Utils import *\n",
    "db = VectorDatabase()\n",
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:4000\"\n",
    "db.initialize_process(chunk_size=400 ,chunk_overlap=300)\n",
    "from Utils import *\n",
    "retriever = Retriever()\n",
    "retriever.process_questions(method='Vector')\n",
    "\n",
    "evaluator = Evaluation()\n",
    "\n",
    "evaluator.output_evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "from typing import List\n",
    "\n",
    "def chinese_tokenizer(text: str) -> List[str]:\n",
    "    # Use jieba to segment Chinese text\n",
    "    return list(jieba.cut(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer parameter is deprecated and will be removed in a future release. Use a stemmer from PyStemmer instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "= VectorDatabase initialized =\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.retrievers.bm25 import BM25Retriever\n",
    "from llama_index.core import Document\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core.response.notebook_utils import display_source_node\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "import pickle\n",
    "import chromadb\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore  \n",
    "from typing import List\n",
    "\n",
    "# Initialize embedding model\n",
    "my_embedding = HuggingFaceEmbedding(\n",
    "    model_name=\"TencentBAC/Conan-embedding-v1\"  # Options: \"TencentBAC/Conan-embedding-v1\", \"sensenova/piccolo-base-zh\"\n",
    ")\n",
    "\n",
    "documents = [Document(text=\"床前明月光\"),\n",
    "             Document(text=\"疑是地上霜\"),\n",
    "             Document(text=\"舉頭望明月\"),\n",
    "             Document(text=\"低頭思故鄉\")]\n",
    "\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.core import VectorStoreIndex, Document, StorageContext\n",
    "# # load documents\n",
    "# with open('./reference/insurance.pkl', 'rb') as file:\n",
    "#     corpus_dict = pickle.load(file)\n",
    "\n",
    "from Utils import *    \n",
    "db = VectorDatabase()\n",
    "vector_index = db.get_vector_index('faq')\n",
    "\n",
    "                \n",
    "# documents = []\n",
    "# for id, text in corpus_dict.items():\n",
    "#     doc = Document(\n",
    "#         text=text, \n",
    "#         id_=f\"doc_id_{id}\",\n",
    "#         metadata={\"category\": 'insurance', \"pid\": id}\n",
    "#     )\n",
    "#     documents.append(doc)\n",
    "# from llama_index.core.storage.docstore import SimpleDocumentStore\n",
    "# docstore = SimpleDocumentStore()\n",
    "\n",
    "# splitter = SentenceSplitter(chunk_size=256)\n",
    "# chroma_collection = chromadb.PersistentClient('./chroma').get_or_create_collection('test')\n",
    "# vector_store =ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "# nodes = splitter.get_nodes_from_documents(documents)\n",
    "# docstore.add_documents(nodes)\n",
    "# vector_index = VectorStoreIndex(\n",
    "#             nodes=nodes,\n",
    "#             embed_model=my_embedding,\n",
    "#             storage_context=StorageContext.from_defaults(vector_store=vector_store)\n",
    "#         )\n",
    "\n",
    "# StorageContext.from_defaults(docstore=docstore).docstore.persist('./docstore/test.json')\n",
    "\n",
    "# docstore = SimpleDocumentStore.from_persist_path('./docstore/test.json')\n",
    "# storage_context = StorageContext.from_defaults(docstore=docstore, vector_store=vector_store)\n",
    "# vector_index = VectorStoreIndex(\n",
    "#     nodes=[], \n",
    "#     storage_context=storage_context,\n",
    "#     embed_model=my_embedding\n",
    "#     )\n",
    "\n",
    "def chinese_tokenizer(text: str) -> List[str]:\n",
    "        # Use jieba to segment Chinese text\n",
    "        return list(jieba.cut(text))\n",
    "\n",
    "retriever = BM25Retriever.from_defaults(\n",
    "    docstore=vector_index.docstore,\n",
    "    similarity_top_k=2,\n",
    "    tokenizer=chinese_tokenizer,\n",
    "    \n",
    ")\n",
    "\n",
    "nodes = retriever.retrieve(\"故乡\")\n",
    "\n",
    "nodes[0].score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "256 100 \n",
    "  \n",
    "= Ground truth accuracy =  \n",
    "\n",
    "Retrieval accuracy: 84.67% \n",
    "\n",
    "Category: insurance, Accuracy: 90.00% \n",
    "\n",
    "Category: finance, Accuracy: 68.00% \n",
    "\n",
    "Category: faq, Accuracy: 96.00% \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "256 200 \n",
    "\n",
    "= Ground truth accuracy = \n",
    "\n",
    "Retrieval accuracy: 86.00% \n",
    "\n",
    "Category: insurance, Accuracy: 88.00% \n",
    "\n",
    "Category: finance, Accuracy: 74.00% \n",
    "\n",
    "Category: faq, Accuracy: 96.00% \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "512 256  \n",
    "\n",
    "= Ground truth accuracy = \n",
    "\n",
    "Retrieval accuracy: 83.33% \n",
    "\n",
    "Category: insurance, Accuracy: 84.00% \n",
    "\n",
    "Category: finance, Accuracy: 70.00% \n",
    "\n",
    "Category: faq, Accuracy: 96.00% \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "128 64\n",
    "\n",
    "Retrieval accuracy: 79.33% \n",
    "\n",
    "Category: insurance, Accuracy: 86.00% \n",
    "\n",
    "Category: finance, Accuracy: 56.00% \n",
    "\n",
    "Category: faq, Accuracy: 96.00%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "512 400 \n",
    "\n",
    "= VectorDatabase initialized = \n",
    "\n",
    "= Retriever initialized = \n",
    "\n",
    "= Ground truth accuracy = \n",
    "\n",
    "Retrieval accuracy: 84.67% \n",
    "\n",
    "Category: insurance, Accuracy: 88.00% \n",
    "\n",
    "Category: finance, Accuracy: 70.00% \n",
    "\n",
    "Category: faq, Accuracy: 96.00%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "512 450 \n",
    " \n",
    "= VectorDatabase initialized = \n",
    "\n",
    "= Retriever initialized = \n",
    "\n",
    "= Ground truth accuracy = \n",
    "\n",
    "Retrieval accuracy: 83.33% \n",
    "\n",
    "Category: insurance, Accuracy: 84.00% \n",
    "\n",
    "Category: finance, Accuracy: 70.00% \n",
    "\n",
    "Category: faq, Accuracy: 96.00%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "256 50 \n",
    "\n",
    "= VectorDatabase initialized = \n",
    "\n",
    "= Retriever initialized = \n",
    "\n",
    "= Ground truth accuracy = \n",
    "\n",
    "Retrieval accuracy: 84.00% \n",
    "\n",
    "Category: insurance, Accuracy: 90.00% \n",
    "\n",
    "Category: finance, Accuracy: 66.00% \n",
    "\n",
    "Category: faq, Accuracy: 96.00%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "128 100 \n",
    "\n",
    "= VectorDatabase initialized = \n",
    "\n",
    "= Retriever initialized = \n",
    "\n",
    "= Ground truth accuracy = \n",
    "\n",
    "Retrieval accuracy: 81.33% \n",
    "\n",
    "Category: insurance, Accuracy: 86.00% \n",
    "\n",
    "Category: finance, Accuracy: 62.00% \n",
    "\n",
    "Category: faq, Accuracy: 96.00%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1024 512 \n",
    " \n",
    "Retrieval accuracy: 82.00% \n",
    "\n",
    "Category: insurance, Accuracy: 76.00% \n",
    "\n",
    "Category: finance, Accuracy: 74.00% \n",
    "\n",
    "Category: faq, Accuracy: 96.00%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "poetry3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
