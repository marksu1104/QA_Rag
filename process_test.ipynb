{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data and Construct VectorDatabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resource module not available on Windows\n",
      "< VectorDatabase initialized > \n",
      "  - loading data into ChromaDB \n",
      "     - loading [faq] ...\n",
      "        ... collection [faq] deleted.\n",
      "     - loading [insurance] ...\n",
      "        ... collection [insurance] deleted.\n",
      "     - loading [finance] ...\n",
      "        ... collection [finance] deleted.\n"
     ]
    }
   ],
   "source": [
    "from Utils import *\n",
    "import os\n",
    "\n",
    "# initialize the database\n",
    "db = VectorDatabase()\n",
    "\n",
    "# gpu if available\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:4000\"\n",
    "\n",
    "# initialize the database\n",
    "db.initialize_process(chunk_size=256 ,chunk_overlap=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< VectorDatabase initialized > \n",
      "< Retriever initialized > \n",
      "  - Answers saved to output.json \n",
      "< Evaluation by Ground Truths > \n",
      "  - Retrieval accuracy: 87.33%\n",
      "     - Category: [insurance], Accuracy: 90.00%\n",
      "     - Category: [finance], Accuracy: 74.00%\n",
      "     - Category: [faq], Accuracy: 98.00%\n",
      "\n",
      "Category: insurance\n",
      "  - QID: 2, Expected: 428, Actual: 578, Source: [475, 325, 578, 428, 606, 258, 275, 565], Query: 本公司應在效力停止日前多少天以書面通知要保人？\n",
      "  - QID: 4, Expected: 186, Actual: 179, Source: [186, 627, 536, 179, 174, 178], Query: 本契約內容的變更應經由誰同意並批註？\n",
      "  - QID: 11, Expected: 7, Actual: 325, Source: [241, 258, 141, 298, 357, 325, 7], Query: 保單借款的可借金額上限如何決定？\n",
      "  - QID: 29, Expected: 578, Actual: 524, Source: [527, 256, 102, 578, 524, 236, 431], Query: 被保險人於本契約有效期間內身故，本公司是否會依本契約約定給付保險金？\n",
      "  - QID: 47, Expected: 620, Actual: 243, Source: [620, 476, 243, 337, 182, 536, 179, 596], Query: 保單年度數是如何計算的?\n",
      "\n",
      "Category: finance\n",
      "  - QID: 53, Expected: 351, Actual: 145, Source: [178, 145, 344, 883, 694, 351, 736, 611], Query: 長榮於2022年第3季的合併權益變動表中，歸屬於母公司業主之本期綜合損益總額為多少新台幣仟元？\n",
      "  - QID: 61, Expected: 900, Actual: 41, Source: [41, 70, 359, 870, 900, 951, 59], Query: 鴻海在2023年第1季度中，集團存貨之帳面金額是多少？\n",
      "  - QID: 62, Expected: 591, Actual: 1024, Source: [89, 721, 971, 56, 1024, 591], Query: 2022年第3季聯發科的現金及約當現金金額是多少？\n",
      "  - QID: 67, Expected: 1021, Actual: 386, Source: [994, 141, 386, 837, 213, 80, 1021], Query: 在2022年第3季度，瑞昱公司有哪些專利訴訟案件被提起且目前正在處理中？\n",
      "  - QID: 69, Expected: 981, Actual: 545, Source: [545, 182, 396, 978, 192, 981], Query: 瑞昱2022年第1季合併財務報表中提到的本期淨利是多少？\n",
      "  - QID: 70, Expected: 490, Actual: 298, Source: [298, 272, 147, 490, 495], Query: 智邦科技股份有限公司2023年第1季的綜合損益總額是多少？\n",
      "  - QID: 75, Expected: 71, Actual: 344, Source: [178, 145, 344, 883, 694, 351, 736, 611, 71], Query: 在2022年第3季，長榮公司有無從事衍生工具交易的情事？\n",
      "  - QID: 79, Expected: 65, Actual: 550, Source: [714, 355, 300, 633, 550, 65, 912, 947], Query: 和泰車公司在2022年第3季產品出售當期列為銷貨收入之何項？\n",
      "  - QID: 82, Expected: 831, Actual: 590, Source: [590, 679, 373, 188, 838, 831, 33], Query: 研華公司在2022年第3季的合併總損益是多少？\n",
      "  - QID: 86, Expected: 189, Actual: 525, Source: [658, 813, 897, 757, 525, 189], Query: 瑞昱在2023年第3季有關涉於哪些專利訴訟，並且這些案件目前進展如何？\n",
      "  - QID: 93, Expected: 660, Actual: 321, Source: [321, 382, 366, 920, 21, 115, 873, 660], Query: 中鋼在2022年第1季提供予銀行作為擔保的資產總帳面價值是多少？\n",
      "  - QID: 99, Expected: 372, Actual: 693, Source: [283, 483, 693, 895, 631, 372], Query: 中鋼在2022年第3季的綜合損益總額是多少？\n",
      "  - QID: 100, Expected: 273, Actual: 63, Source: [682, 944, 984, 467, 362, 781, 96, 63, 273], Query: 鴻海2022年第1季各部門外部收入分別是多少?\n",
      "\n",
      "Category: faq\n",
      "  - QID: 135, Expected: 28, Actual: 399, Source: [399, 271, 562, 28, 233, 498, 53, 458, 470, 432, 319, 299, 431, 358, 426], Query: 誰可以申辦玉山e指信貸\n"
     ]
    }
   ],
   "source": [
    "from Utils import *\n",
    "\n",
    "# initialize the retriever\n",
    "retriever = Retriever()\n",
    "# do question \n",
    "retriever.process_questions(method='Vector')\n",
    "\n",
    "# evaluate the accuracy\n",
    "evaluator = Evaluation()\n",
    "evaluator.output_evaluation()\n",
    "evaluator.output_incorrect_answers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BM25 Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resource module not available on Windows\n",
      "< VectorDatabase initialized > \n",
      "< Retriever initialized > \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\marks\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.636 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Answers saved to output.json \n",
      "< Evaluation by Ground Truths > \n",
      "  - Retrieval accuracy: 72.67%\n",
      "     - Category: [insurance], Accuracy: 82.00%\n",
      "     - Category: [finance], Accuracy: 44.00%\n",
      "     - Category: [faq], Accuracy: 92.00%\n"
     ]
    }
   ],
   "source": [
    "from Utils import *\n",
    "\n",
    "# initialize the retriever\n",
    "retriever = Retriever()\n",
    "# do question \n",
    "retriever.process_questions(method='original')\n",
    "\n",
    "# evaluate the accuracy\n",
    "evaluator = Evaluation()\n",
    "evaluator.output_evaluation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BM25 + Vector Fusion Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resource module not available on Windows\n",
      "< VectorDatabase initialized > \n",
      "< Retriever initialized > \n",
      "  - Answers saved to output.json \n",
      "< Evaluation by Ground Truths > \n",
      "  - Retrieval accuracy: 88.00%\n",
      "     - Category: [insurance], Accuracy: 94.00%\n",
      "     - Category: [finance], Accuracy: 74.00%\n",
      "     - Category: [faq], Accuracy: 96.00%\n"
     ]
    }
   ],
   "source": [
    "from Utils import *\n",
    "\n",
    "# initialize the retriever\n",
    "retriever = Retriever()\n",
    "# do question \n",
    "retriever.process_questions(method='BM25_Vector')\n",
    "\n",
    "# evaluate the accuracy\n",
    "evaluator = Evaluation()\n",
    "evaluator.output_evaluation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Llama index BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< VectorDatabase initialized > \n",
      "< Retriever initialized > \n",
      "  - Answers saved to output.json \n",
      "< Evaluation by Ground Truths > \n",
      "  - Retrieval accuracy: 82.67%\n",
      "     - Category: [insurance], Accuracy: 98.00%\n",
      "     - Category: [finance], Accuracy: 60.00%\n",
      "     - Category: [faq], Accuracy: 90.00%\n"
     ]
    }
   ],
   "source": [
    "from Utils import *\n",
    "\n",
    "# initialize the retriever\n",
    "retriever = Retriever()\n",
    "# do question \n",
    "retriever.process_questions(method='BM25')\n",
    "\n",
    "# evaluate the accuracy\n",
    "evaluator = Evaluation()\n",
    "evaluator.output_evaluation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Utils import *\n",
    "\n",
    "# initialize the retriever\n",
    "retriever = Retriever()\n",
    "# do question \n",
    "retriever.process_questions(method='weight')\n",
    "\n",
    "# evaluate the accuracy\n",
    "evaluator = Evaluation()\n",
    "evaluator.output_evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< VectorDatabase initialized > \n",
      "< Retriever initialized > \n",
      "  - Answers saved to output.json \n",
      "< Evaluation by Ground Truths > \n",
      "  - Retrieval accuracy: 87.33%\n",
      "     - Category: [insurance], Accuracy: 92.00%\n",
      "     - Category: [finance], Accuracy: 72.00%\n",
      "     - Category: [faq], Accuracy: 98.00%\n"
     ]
    }
   ],
   "source": [
    "from Utils import *\n",
    "\n",
    "# initialize the retriever\n",
    "retriever = Retriever()\n",
    "# do question \n",
    "retriever.process_questions(method='weight',combine_method='weighted')\n",
    "\n",
    "# evaluate the accuracy\n",
    "evaluator = Evaluation()\n",
    "evaluator.output_evaluation()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "poetry3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
